{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9chkLJcd226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b14431c-8b56-4916-ce89-54b4f82f8138"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install openai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9853RCHId6-2"
      },
      "source": [
        "import json\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"insert api key here\"     \n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class gpt4:\n",
        "    def __init__(self, basictext):\n",
        "        print('gpt4 initialized')\n",
        "        self.basic_text = [\n",
        "            {\"role\": \"system\", \"content\": basictext},\n",
        "        ]\n",
        "        self.chat_history = []\n",
        "\n",
        "    def output(self, reaction):\n",
        "        MODEL = \"gpt-4\"\n",
        "        print('gpt4 processing input')\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=MODEL,\n",
        "            messages= self.basic_text + [{\"role\": \"user\", \"content\": reaction}],\n",
        "            temperature=0,\n",
        "        )\n",
        "        self.chat_history += [{\"role\": \"user\", \"content\": reaction}] + [{\"role\": \"assistant\", \"content\": response[\"choices\"][0][\"message\"][\"content\"]}]\n",
        "        return response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "tNH56kjdiZQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_instructions = \"\"\"\n",
        "You are a resume processing AI. You improve grammar, make resumes more effective in reaching the right audience, and improve writing style and make it more concise.\n",
        "User input text is usually their complete resume. They might include wishes and specific instructions of resume changes.\n",
        "Your output is their improved and rewritten resume. You do not output anything else.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "resumeGPT = gpt4(basic_instructions)"
      ],
      "metadata": {
        "id": "GxSBmS2ek5xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20a151a-345c-4afe-bb55-7b9c381e077c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt4 initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"\"\"\n",
        "rewrite the following resume to make it more concise and effective in convincing recruiters looking for a data scientist.\n",
        "Also add a description for any jobs that don't have a description right now.\n",
        "\n",
        "INSERT RESUME TEXT HERE\n",
        "\n",
        "\"\"\"\n",
        "data = resumeGPT.output(instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QUOTrurk7IY",
        "outputId": "44de72d6-4cf1-440b-e43b-77e9e17fd88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt4 processing input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU9TzGk9lIIX",
        "outputId": "5ee40d5c-ed34-4e62-d928-d83942fb2664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contact Information\n",
            "bob.tuynman@gmail.com\n",
            "www.linkedin.com/in/bobtuynman\n",
            "(LinkedIn)\n",
            "\n",
            "Bob Tuynman\n",
            "Data Scientist\n",
            "Den Haag, Zuid-Holland, Nederland\n",
            "\n",
            "Summary\n",
            "Highly motivated data scientist with a passion for continuous improvement, experienced in research, teaching, and industry applications. Strong foundation in Industrial Engineering and Management, with an M.Sc in Data Science and Society. Seeking opportunities to apply and expand expertise in data science.\n",
            "\n",
            "Key Skills\n",
            "- Machine Learning\n",
            "- Python\n",
            "- MySQL\n",
            "\n",
            "Languages\n",
            "- Dutch (Native or Bilingual)\n",
            "- English (Native or Bilingual)\n",
            "- Spanish (Elementary)\n",
            "- French (Elementary)\n",
            "- Papiamento (Limited Working)\n",
            "\n",
            "Certifications\n",
            "- Hierarchical and Recursive Queries in SQL Server\n",
            "- Intro to SQL for Data Science\n",
            "- Microsoft Project Certification\n",
            "- Intermediate SQL Server\n",
            "- Intro to Python for Data Science\n",
            "\n",
            "Experience\n",
            "De Haagse Hogeschool / The Hague University of Applied Sciences\n",
            "Data Scientist/Research Scientist (Lectorate Data Science) (Feb 2022 - Present)\n",
            "- Conducting research and developing data-driven solutions in a data science-focused group.\n",
            "\n",
            "Lecturer Data Science & AI (Jan 2022 - Present)\n",
            "- Teaching data science and AI courses at an applied university.\n",
            "\n",
            "Amazon\n",
            "Business Intelligence Engineer (Feb 2021 - Jul 2021)\n",
            "- Developed data-driven solutions to optimize business processes and decision-making.\n",
            "\n",
            "Primaned\n",
            "Data Analyst / Business Intelligence Consultant (Apr 2019 - Feb 2021)\n",
            "- Assisted clients in answering project control questions using data-driven solutions.\n",
            "\n",
            "OCS Workplaces\n",
            "Business Analyst + Graduating Intern (Dec 2017 - Aug 2018)\n",
            "- Conducted research to determine the next step in data maturity for the sales department, resulting in customer profiles and machine learning models for predicting ideal clients.\n",
            "\n",
            "De Haagse Hogeschool / The Hague University of Applied Sciences\n",
            "Committee Member P&O of the University Council (Jun 2016 - Sep 2017)\n",
            "- Collaborated with the Board of Directors on policy decisions and discussed organizational, educational, and personnel matters.\n",
            "\n",
            "Chairman of the Program Committee for Technical Business Administration (Feb 2015 - Jun 2016)\n",
            "- Led a 10-member committee to maintain the quality of education in Technical Business Administration, evaluating regulations, providing feedback, and mediating conflicts.\n",
            "\n",
            "Committee Member of the Program Committee (Oct 2014 - Feb 2015)\n",
            "- Participated in a 10-member committee to maintain the quality of education in Technical Business Administration.\n",
            "\n",
            "Louwman Dealer Group\n",
            "Intern Process Optimization After Sales (Sep 2016 - Feb 2017)\n",
            "- Analyzed the After Sales process and delivered an implementation plan based on the \"7 Mudas\" of the Toyota Production System.\n",
            "\n",
            "Tix S.C.\n",
            "General Director (Mar 2015 - Aug 2015)\n",
            "- Co-founded a student company that sold stickers indicating smoking in rooms, reaching the semi-finals of the national \"Young Entrepreneur\" competition.\n",
            "\n",
            "Royal Marine\n",
            "Freelance Yacht Builder, Repair, and Maintenance (Jan 2011 - Apr 2014)\n",
            "- Performed weekly maintenance for clients, including electronic and engine maintenance, boat carpentry, and yacht restoration.\n",
            "\n",
            "Seatech Services\n",
            "Yacht Restoration/Boat Carpentry (Jan 2009 - Jan 2011)\n",
            "- Conducted yacht restoration and boat carpentry, 3D modeling, CAD design, and composite work with polyester and epoxy resins, fiberglass, gelcoat applications, and trim and rig work.\n",
            "\n",
            "Education\n",
            "Tilburg University\n",
            "Master of Science - MS, Data Science (2020 - 2022)\n",
            "\n",
            "University of Amsterdam\n",
            "Pre-Master, Data Science (2019 - 2020)\n",
            "\n",
            "De Haagse Hogeschool / The Hague University of Applied Sciences\n",
            "Bachelor of Science (B.Sc.), Technical Business Administration (2014 - 2018)\n",
            "\n",
            "University of the Netherlands Antilles\n",
            "HBO Marketing Management (2007 - 2009)\n"
          ]
        }
      ]
    }
  ]
}